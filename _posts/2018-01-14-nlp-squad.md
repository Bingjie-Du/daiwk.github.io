---
layout: post
category: "nlp"
title: ""
tags: [normalization, bn, ln]
---

目录

<!-- TOC -->

- [SLQA](#slqa)
    - [整体思路](#整体思路)
    - [SLQA架构](#slqa架构)
- [相关模型](#相关模型)
    - [基本模型](#基本模型)
    - [Match-LSTM[4]](#match-lstm4)
- [参考文献](#参考文献)

<!-- /TOC -->

参考 [机器阅读理解打破人类记录，解读阿里iDST SLQA技术](https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650736188&idx=2&sn=03793343fabba546cafd9540be0f8277&chksm=871ac242b06d4b54283e7926a91dd4aff8a9480acd4f79a57785822c080dc8e027da96b1d04f&mpshare=1&scene=1&srcid=0114a1kagAyjzKDjM5D8be80&pass_ticket=maZ8vJqYz24CXvI%2FR2qg58OsViKCicnkKXyOdUjO2Iy11TDgRJHxroNhcwnQ9Lne#rd)

SQuAD 数据集是行业内公认的机器阅读理解标准水平测试，也是该领域顶级赛事，被誉为机器阅读理解界的 ImageNet（图像识别领域的顶级赛事）。

SQuAD 是由 Rajpurkar 等人[1]提出的一个最新的阅读理解数据集。该数据集包含 10 万个（问题，原文，答案）三元组，原文来自于 536 篇维基百科文章，而问题和答案的构建主要是通过众包的方式，让标注人员提出最多 5 个基于文章内容的问题并提供正确答案，且答案出现在原文中。SQuAD 和之前的完形填空类阅读理解数据集如 CNN/DM[2]，CBT[3]等最大的区别在于：**SQuAD 中的答案不在是单个实体或单词，而可能是一段短语**，这使得其答案更难预测。SQuAD 包含公开的训练集和开发集，以及一个隐藏的测试集，其采用了与 ImageNet 类似的封闭评测的方式，研究人员需提交算法到一个开放平台，并由 SQuAD 官方人员进行测试并公布结果。

机器阅读理解的评测维度分为 EM（Exact Match，精准匹配分数）和 F1（精确率和召回率的平均，模糊匹配分数）。

## SLQA

本次阿里巴巴参与测评的系统名为 SLQA，Semantic Learning for Question Answering，是 iDST NLP 团队提出的「基于分层融合注意力机制」的深度神经网络系统。评测证明，相比传统方法，SLQA 的效果取得了显著的提升。

采用传统方法解决机器阅读理解问题，一般会将该过程分为以下几个步骤：

+ 对问题、篇章分别进行词法、句法分析，针对分析结果进行特征提取：
+ 基于特征采用诸如 LR、CRF 等模型进行答案边界预测；
+ 采用梯度下降类算法在训练集上进行优化，拟合数据分布。

在此过程中，基础语言模型、依存分析等模块的准确率在一定程度上会影响训练效果，特征工程的优劣也同样左右着是否能训练得到可用的模型。

### 整体思路

人类在进行阅读理解时，常见思维顺序如下：

1. 通读篇章，理解文章主题和大体内容；读题，了解提问内容及关注点。
2. 带着问题找答案，将问题同篇章做关联，并结合篇章主题，理解问题重点。
3. 定位可能的答案范围，并再次重点阅读附近文字。
4. 为避免忘记问题，再次审题，并结合 3. 中重点区域进行答案圈选。
5. 针对挑出的答案候选进行精筛，确定最正确的答案。


因此，构建模型的主要思想是在捕捉**问题和文章中特定区域关联**的同时，借助分层策略，**逐步集中注意力**，使答案边界清晰。

同时，为了避免过于关注细节，**采用融合方式将全局信息加入注意力机制**，进行适度纠正，确保关注点正确。这种逐步聚焦并兼顾全局的方式与其他参赛者已经公布的的做法不太相同，也是团队此次刷榜登顶的关键所在。

### SLQA架构

<html>
<br/>
<img src='../assets/slqa_framework.png' style='max-height: 300px'/>
<br/>
</html>

目前业界主流的基于 End2End 学习的机器阅读理解模型主要为**Encode-Interaction-Pointer框架**。

SLQA 系统包含如下基本结构：**Encoder Layer（文本表征）**，**Attention Layer（注意力机制）**，**Match Layer（问题篇章匹配）**以及 **Output Layer（答案预测）**。


+ **Encoder Layer**: 用于表示学习，可以理解为语言模型层，用以将篇章及问题从离散字符转变为蕴含语义的表征向量。团队采用了**多层双向 LSTM** 并分别对篇章和问题进行主题和重点词关注。
+ **Attention Layer**: 得到有效的问题及篇章表征后，为表达依据问题定位答案过程，缩小备选答案查找范围，将搜索空间通过注意力机制约束，主要进行**多层融合注意力表示**，对问题和篇章进行相关性对齐（Align），并不断补充全局信息（Fusion），每一次对齐都基于下层信息并在此基础上更加细化（paragraph→sentence→phrase→word），采用的方式分别为 **Co-Attention（篇章到问题，问题到篇章）**，**Self-Attention（问题自身，篇章自身）**。
+ **Match Layer**: 用于做融合信息后的问题和篇章匹配，团队采用**双线性矩阵**来学习经过多层信息过滤后的篇章和问题匹配参数，由于在前一阶段无关信息已经被过滤，最后的匹配可完成答案的定位工作。
+ **Output Layer**: 结合匹配信息对篇章中词汇进行标注，预测相应词汇是答案开始位置或结束位置的概率。之后，模型会抽取可能性最高的一段连续文本作为答案。

重点探索和研究的Layer是第三层（Hierarchical Attention Fusion Network）。

## 相关模型

参考[PaperWeekly 第38期 \| SQuAD综述](https://zhuanlan.zhihu.com/p/27015318)

### 基本模型

由于 SQuAD 的答案限定于来自原文，模型只需要判断原文中哪些词是答案即可，因此是一种抽取式的 QA 任务而不是生成式任务。

几乎所有做 SQuAD 的模型都可以概括为同一种框架：Embed 层，Encode 层，Interaction 层和 Answer 层。
+ Embed 层负责将原文和问题中的 tokens 映射为向量表示；
+ Encode 层主要使用 RNN 来对原文和问题进行编码，这样编码后每个 token 的向量表示就蕴含了上下文的语义信息；
+ Interaction 层是大多数研究工作聚焦的重点，该层主要负责捕捉问题和原文之间的交互关系，并输出编码了问题语义信息的原文表示，即 query-aware 的原文表示；
+ 最后 Answer 层则基于 query-aware 的原文表示来预测答案范围。

<html>
<br/>
<img src='../assets/qa_framework.jpg' style='max-height: 300px'/>
<br/>
</html>


### Match-LSTM[4]

<html>
<br/>
<img src='../assets/match_lstm.jpg' style='max-height: 300px'/>
<br/>
</html>



## 参考文献

[1] Pranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, and Percy Liang. 2016. Squad: 100,000+ questions for machine comprehension of text. In Proceedings of EMNLP.

[2] Karl Moritz Hermann, Tomas Kocisky, Edward Grefenstette, Lasse Espeholt, Will Kay, Mustafa Suleyman, , and Phil Blunsom. 2015. Teaching ma- chines to read and comprehend. In Proceedings of NIPS.

[3] Felix Hill, Antoine Bordes, Sumit Chopra, and Jason Weston. 2016. The goldilocks principle: Reading childrens books with explicit memory representa- tions. In Proceedings of ICLR.

[4] Shuohang Wang and Jing Jiang. 2017. Machine comprehension using match-lstm and answer pointer. In Proceedings of ICLR.

[5] Minjoon Seo, Aniruddha Kembhavi, Ali Farhadi, and Hananneh Hajishirzi. 2017. Bidirectional attention flow for machine comprehension. In Proceedings of ICLR.

[6] Caiming Xiong, Victor Zhong, and Richard Socher. 2017. Dynamic coattention networks for question answering. In Proceedings of ICLR.

[7] Zhiguo Wang, Haitao Mi, Wael Hamza, and Radu Florian. 2016. Multi-perspective context matching for machine comprehension. arXiv preprint arXiv:1612.04211 .

[8] Dirk Weissenborn, Georg Wiese, and Laura Seiffe. 2017. Fastqa: A simple and efficient neural architecture for question answering. arXiv preprint arXiv:1703.04816 .

[9] Junbei Zhang, Xiaodan Zhu, Qian Chen, Lirong Dai, Si Wei, and Hui Jiang. 2017. Exploring question understanding and adaptation in neural- network-based question answering. arXiv preprint arXiv:1703.04617 .

[10] Yichen Gong and Samuel R. Bowman. 2017. Ruminating reader: Reasoning with gated multi-hop attention. arXiv preprint arXiv:1704.07415 .

[11] Yelong Shen, Po-Sen Huang, Jianfeng Gao, and Weizhu Chen. 2016. Reasonet: Learning to stop reading in machine comprehension. arXiv preprint arXiv:1609.05284 .

[12] Sainbayar Sukhbaatar, Arthur Szlam, Jason Weston, and Rob Fergus. 2015. End-to-end memory networks. In Proceedings of NIPS.

[13] Microsoft Research Asia. 2017. R-NET: MACHINE READING COMPREHENSION WITH SELF-MATCHING NETWORKS. In Proceedings of ACL.

[14] Minghao Hu, Yuxing Peng, and Xipeng Qiu. 2017. Mnemonic Reader for Machine Comprehension. arXiv preprint arXiv:1705.02798 .