---
layout: post
category: "ml"
title: "梯度下降优化算法"
tags: [梯度下降优化算法, momentum, NAG, Adagrad, Adadelta, RMSprop, Adam]
---

## 梯度下降

## momentum

```
v_t=\gamma v_{t-1}+ \eta \triangledown _\theta\triangledown J(\theta)
\theta=\theta-v_t    
```

## NAG

## Adagrad

## Adadelta

## RMSprop

## Adam

