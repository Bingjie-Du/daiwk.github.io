---
layout: post
category: "cv"
title: "经典cnn模型们"
tags: [cnn]
---

## cnn basic

### 卷积

[ufldl-卷积特征提取](http://deeplearning.stanford.edu/wiki/index.php/%E5%8D%B7%E7%A7%AF%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96)

自然图像有其固有特性，也就是说，图像的一部分的统计特性与其他部分是一样的。这也意味着我们在这一部分学习的特征也能用在另一部分上，所以对于这个图像上的所有位置，我们都能使用同样的学习特征。

更恰当的解释是，当从一个大尺寸图像中随机选取一小块，比如说 8x8 作为样本，并且从这个小块样本中学习到了一些特征，这时我们可以把从这个 8x8 样本中学习到的特征作为探测器，应用到这个图像的任意地方中去。特别是，我们可以用从 8x8 样本中所学习到的特征跟原本的大尺寸图像作卷积，从而对这个大尺寸图像上的任一位置获得一个不同特征的激活值。

下面给出一个具体的例子：假设你已经从一个 96x96 的图像中学习到了它的一个 8x8 的样本所具有的特征，假设这是由有 100 个隐含单元的自编码完成的。为了得到卷积特征，需要对 96x96 的图像的每个 8x8 的小块图像区域都进行卷积运算。也就是说，抽取 8x8 的小块区域，并且从起始坐标开始依次标记为（1，1），（1，2），...，一直到（89，89），然后对抽取的区域逐个运行训练过的稀疏自编码来得到特征的激活值。在这个例子里，显然可以得到 100 个集合，每个集合含有 89x89 个卷积特征。

![](../assets/convolution.gif)

假设给定了`\(r \times c\)`的大尺寸图像，将其定义为`\(x_{large}\)`。首先通过从大尺寸图像中抽取的`\(a \times b\)`的小尺寸图像样本`\(x_{small}\)`训练稀疏自编码，计算`\(f = \sigma (W^{(1)}x_{small} + b^{(1)})\)`（`\(\sigma \)`是一个 sigmoid 型函数）得到了k个特征， 其中`\(W^{(1)}\)` 和`\(b^{(1)}\)`是可视层单元和隐含单元之间的权重和偏差值。对于每一个`\(a \times b\)`大小的小图像`\(x_s\)`，计算出对应的值`\(f_s = \sigma (W^{(1)}x_s + b^{(1)})\)`，对这些`\(f_{convolved}\)`值做卷积，就可以得到`\(k \times (r - a + 1) \times (c - b + 1)\)`个卷积后的特征的矩阵。

### 池化

[ufldl-池化](http://deeplearning.stanford.edu/wiki/index.php/%E6%B1%A0%E5%8C%96)

## 发展历程

包括lenet, alexnet, vgg, googlenet, resnet等。

inception发展过程：
[http://blog.csdn.net/u010402786/article/details/52433324](http://blog.csdn.net/u010402786/article/details/52433324)
